<html>
<head>
<title>What is Reinforcement Learning? A Complete Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>什么是强化学习？完全指南</h1>
<blockquote>原文：<a href="https://hackr.io/blog/reinforcement-learning#0001-01-01">https://hackr.io/blog/reinforcement-learning#0001-01-01</a></blockquote><div><div class="content">
										<h2 id="introduction"><strong>简介</strong></h2>
<p>机器学习模型的训练有助于在代理学习如何在模糊和潜在复杂的环境中完成目标时做出一系列决策。每当人工智能面临强化学习(类似于游戏学习)的情况时，计算机就会通过试错法努力寻找问题的解决方案。此外，对人工智能系统的行为给予奖励或惩罚，以确保机器遵循其指挥官或程序员的指令。虽然奖励政策是由设计师制定的，设计师没有提供解决游戏的建议或提示，但完全是在模型上找到如何执行任务以增加奖励，从没有技能开始，到用复杂的战术和出色的技能完成。借助搜索和多次尝试的力量，强化学习已经成为暗示机器创造力的最有效方式。与人类截然不同的是，当强化学习算法在足够强大的计算机基础设施上运行时，<a href="https://hackr.io/blog/what-is-artificial-intelligence">人工智能</a>可以从数以千计的对齐游戏中收集经验。</p>
<h3 id="examples-of-reinforcement-learning"><strong>强化学习的例子</strong></h3>
<p>强化学习的应用早先受到效率较低的计算机基础设施的限制。随着强大的新计算技术的出现，早期的进展正在迅速改变，新计算技术正在引入全新的鼓舞人心的应用。</p>
<p>在强化学习训练中，控制自动驾驶汽车的模型可以被认为是一个潜在应用的优秀例子。在理想情况下，计算机不会得到驾驶汽车的指令。程序员可以避免硬连线任何与任务相关的东西，这将允许机器从错误中学习。在准确的情况下，硬件元素将是奖励函数。</p>
<p>例如，在正常情况下，我们需要一辆自动驾驶汽车将安全放在第一位，减少旅行时间，减少污染，遵守法律规定，并为驾驶者提供舒适的乘坐体验。对于自主赛车来说，速度比驾驶员的舒适度更重要。程序员无法预测路上可能发生的任何事情。程序员开发强化学习代理的方式是，它能够从奖惩系统中学习，而不是构建冗长的“如果-那么”指令。代理人(执行任务的强化学习算法的另一个名字)因达到某个目标而获得奖励。</p>

<h3 id="challenges-with-reinforcement-learning"><strong>强化学习的挑战</strong></h3>
<p>准备模拟环境是强化学习中的主要挑战，它极大地依赖于要完成的任务。当模型必须在国际象棋、围棋或雅达利游戏中成为超人时，开发模拟环境相对简单。在建立一个能够驾驶自动驾驶汽车的模型这件事情上，在让汽车上路之前，制作一个逼真的模拟器是很重要的<strong> </strong>。对于模型来说，学习如何在安全的环境中刹车或避免撞车是很重要的，在安全的环境中，放弃一千辆车至少要付出代价。将模型从培训环境转移到现实世界，在现实世界中，事情变得有问题，这有助于提高学习者在解决问题时应用解决方案和创新想法的能力和技能。</p>
<p>奖惩制度是与网络沟通的唯一途径；没有其他方法可以这样做。这是特定的，可能导致灾难性的遗忘，其中获得一些新知识导致一些旧知识从网络中被抹去。</p>
<p>达到局部最优是另一个挑战——任务是由代理以其本来的方式执行的，但不是以最优或所需的方式。一个像袋鼠一样跳跃的“跳跃者”没有做预期的事情，即行走，可以被认为是一个很好的例子，这可以在我们最近的博客文章中找到。</p>
<p>最终，会有代理人在没有完成设计任务的情况下改革奖金。下面给出的OpenAI视频可以认为是一个有趣的例子；在这种情况下，代理学习获得奖励的方法，但不是完成比赛。</p>
<p><a class="btn btn-primary btn-call-to-action " href="https://click.linksynergy.com/deeplink?id=jU79Zysihs4&amp;mid=39197&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fbeginner-master-rl-1%2F" target="_blank" rel="noopener">强化学习入门到精通Python中的AI</a></p>
<h3 id="machine-learning-vs-deep-learning-vs-reinforcement-learning"><strong>机器学习vs深度学习vs强化学习</strong></h3>
<p>毫无疑问，机器学习、深度学习和强化学习之间没有明确的界限。可以认为是平行四边形–长方形–正方形的关系，其中<a href="https://hackr.io/blog/what-is-machine-learning-definition-types">机器学习</a>属于广播范畴，而深度强化学习是最窄的一个。类似地，强化学习是机器和深度学习技术的一种专门应用形式，旨在以某种方式解决问题。</p>

<p>尽管这些想法似乎不同，但在这些亚型之间没有明显的区别。尽管如此，他们在项目中联合起来；这是因为模型是以这样一种方式准备的，它不拘泥于一种“纯类型”，以便尽可能以更有效的方式执行任务。所以“机器学习、深度学习和强化学习的精确区别是什么”基本上是一个要回答的扭曲问题。</p>
<h3 id="what-is-machine-learning"><strong>什么是机器学习？</strong></h3>
<p>它是人工智能的一种形式，在这种形式中，计算机具有利用数据逐渐提高某项任务的性能的能力，而无需直接控制。当控制器可以为输入到机器学习系统中的每个训练提供标签时，受监督的机器学习就发生了。</p>
<p><strong>例如:</strong>通过调查从煤矿获取的历史数据，deepsense.ai建立了一个自动化系统，可以在地震威胁事件发生前8小时预测它。从24个煤矿中，记录了几个月的地震事件。该模型有能力通过分析前24小时的读数来确认爆炸的可能性。</p>
<p>从人工智能的角度来看，在一个清晰和规范化的数据集上，只有一个模型在执行一项任务。</p>
<p>当模型仅被提供有输入数据时，则<strong>无监督学习</strong>发生。它必须通过挖掘数据来找到隐藏的结构或其中的关系。设计师可能不知道结构是什么，或者机器学习模型要找到什么。我们采用的一个例子是一个激动人心的预测。我们查阅了客户数据，并为类似的集团客户开发了一种算法。然而，这些组不是我们选择的。随着时间的推移，我们可以识别高风险群体(那些高激动率)，我们的客户知道他们应该首先接近哪个客户。</p>
<p>无监督学习的另一个例子是异常检测；算法必须找出不适合该组的元素。这可能是一个潜在的欺诈交易或任何其他与违反规范或有缺陷的产品相关的事件。</p>
<h3 id="what-is-deep-learning">什么是深度学习？</h3>
<p>深度学习有几层神经网络，可以执行更复杂的任务。深度学习模型的构建受到了人脑结构的启发，但进行了简化。深度学习模型有一些神经网络层，原则上负责适度学习关于某些数据的更抽象的特征。虽然深度学习解决方案提供了惊人的结果，但就规模而言，它们在人脑面前不值一提。整个网络作为一个整体进行训练，每一层都使用前一层的结果作为输入。创建人工神经网络并不是一个新的核心概念。扩展采用已经有了像TensorFlow、Keras和PyTorch这样的框架，所有这些都使得构建机器学习模型更加方便。</p>
<p><strong>例子:</strong> deepsense.ai为美国国家海洋和大气管理局(NOAA)开发了一个基于深度学习的模型。它是为了从研究人员点击的航拍照片中识别露脊鲸而开发的。Deepsense.ai与NOAA合作，获取关于濒危物种的更多信息。从技术角度来看，从航拍照片中识别特定的鲸鱼标本是绝对的深度学习。该解决方案有一些执行单独任务的机器学习模型。第一个人的任务是在照片中找到鲸鱼的头部，而第二个人通过切割和旋转照片来平衡照片，最终给出了一张护照大小的单只鲸鱼的照片(统一视图)。</p>
<p>第三个模型负责从之前制作和处理的照片中识别某些鲸鱼。在吹头帽尖处，有一个由500万个神经元组成的网络。超过941，000个神经元在寻找鲸鱼的头部，超过300万个神经元用于区分某些鲸鱼。有900多万个神经元在完成这项任务，这看起来很多，但与人脑中工作的1000多亿个神经元相比还是很少的。后来，我们使用一种熟悉的基于深度学习的解决方案，利用患者视网膜的图像来治疗糖尿病视网膜病变。</p>
<h3 id="what-is-reinforcement-learning"><strong>什么是强化学习？</strong></h3>
<p>强化学习，如前所述，它是一个奖惩系统，迫使计算机自己解决一个问题。人类很少参与改变环境和调整奖惩制度。当计算机增加奖励时，它很可能会寻找意想不到的方法。防止利用系统并激励机器以预期的方式完成任务是人类参与的重点。当没有合适的方法来执行任务时，强化学习是有用的。尽管如此，该模型必须遵守一些规则才能正确履行其职责。比如拿道路代码来说。</p>
<p><strong>例子:</strong>通过调整和寻求深度强化学习的最优策略，我们只需要20分钟就可以做出一个在玩雅达利游戏上达到超人水平的智能体。原则上，相同的算法可以用来为自动驾驶汽车或假肢制造人工智能。给模型一个Atari视频游戏来玩，例如Arkanoid或space invaders，事实上，这是评估强化学习方法的最佳方式之一。正如谷歌大脑的马克·g·贝勒马尔(Marc G. Bellemare)所说，他介绍了雅达利视频游戏作为强化学习基准，“尽管具有挑战性，但这些环境仍然足够简单，我们可以希望在尝试解决这些问题时取得可衡量的进展。”</p>
<p>在某种程度上，如果人工智能将驾驶汽车并学习如何演奏一些雅达利经典音乐，可以被称为一个有意义的中间里程碑。在自动驾驶车辆中，强化学习的潜在应用是一个有趣的案例。设计师无法猜测道路上可能发生的所有情况，因此让模型在不同的环境中学习惩罚和奖励系统实际上是人工智能扩展其拥有和收集的经验的最有效方式。</p>
<h3 id="discriminating-factor-of-reinforcement-learning"><strong>强化学习的判别因子</strong></h3>
<p>强化学习的主要判别因素是代理如何被教导。该模型不是检查给定的数据，而是与环境相互联系，找出增加奖励的方法。以深度强化学习为例，神经网络负责存储经验，从而增强完成任务的方式。</p>
<h2 id="conclusion"><strong>结论</strong></h2>
<p>尽管强化学习、机器学习和深度学习是相互关联的，但它们中的任何一个都不会取代另一个。受人尊敬的法国科学家和脸书“Yann LeCun”的研究负责人开玩笑说，强化学习是蛋糕上的樱桃，机器学习是蛋糕本身，深度学习是糖衣。如果没有前面的重复，樱桃顶端将一无所有。在许多情况下，使用经典的机器学习技术就足够了。不涉及机器学习的纯算法方法似乎在商业数据处理或管理数据库中很有用。</p>
<p><strong>人也在读:</strong></p>


									</div>

									</div>    
</body>
</html>