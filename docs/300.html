<html>
<head>
<title>Difference between Hadoop MapReduce and Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Hadoop MapReduce和Apache Spark的区别</h1>
<blockquote>原文：<a href="https://hackr.io/blog/hadoop-mapreduce-vs-apache-spark#0001-01-01">https://hackr.io/blog/hadoop-mapreduce-vs-apache-spark#0001-01-01</a></blockquote><div><tbody>
<tr>
<td><strong>因素</strong></td>
<td><strong> Hadoop MapReduce </strong></td>
<td><strong>阿帕奇火花</strong></td>
</tr>
<tr>
<td><strong>核心定义</strong></td>
<td>MapReduce is a programming model that is implemented in processing huge amounts of data. <br/>MapReduce has been developed using Java <br/>MapReduce Programs work in two phases:
<ul>
<li>地图阶段</li>
<li>还原阶段</li>
</ul>
<p>整个MapReduce过程经历以下4个阶段:</p>
<ul>
<li><strong>分割</strong>:输入被分割成固定大小的分割，称为input-splits。输入拆分由单个地图消耗。</li>
</ul>
<ul>
<li><strong>映射</strong>:这里，每个映射中的数据被传递到一个映射函数中，以产生输出值。</li>
</ul>
<ul>
<li><strong>混排</strong>:该阶段消耗映射阶段的输出，相关记录合并。</li>
</ul>
<ul>
<li><strong> Reducing </strong>:在这个阶段，相关记录被聚合，返回一个输出值。这个阶段总结了完整的数据集。</li>
</ul>
</td>
<td>Apache Spark是一个用于大数据的开源分布式处理系统。Spark是大规模数据处理的引擎。Spark是使用Scala开发的。<br/>Apache Spark的主要组件如下:<ul>
<li>Apache Spark Core :它是底层的通用执行引擎，所有其他功能都建立在它之上。它在外部存储系统中提供内存计算和数据集引用。</li>
</ul>
<ul>
<li><strong> Spark SQL </strong>:它是提供关于数据结构和正在执行的计算的信息的模块</li>
</ul>
<ul>
<li><strong>火花流</strong>:允许处理实时数据。然后，使用复杂的算法处理这些数据，并将其推送到文件系统、数据库和实时系统中。</li>
</ul>
<ul>
<li><strong> MLlib【机器学习】</strong>:它是一个库，包含了大量的机器学习算法和工具，用于构建、评估和调优ML管道。</li>
</ul>
<ul>
<li>GraphX :它附带了一个库来操作图形数据库和执行计算。它将ETL过程、探索过程和迭代图计算统一在一个系统中。</li>
</ul>
</td>
</tr>
<tr>
<td><strong>加工速度</strong></td>
<td>MapReduce从磁盘读取和写入数据。虽然它比传统系统快，但比Spark慢得多。</td>
<td>它在RAM上运行，将中间数据存储在内存中，减少了对磁盘的读/写周期数。因此，它比传统的MapReduce更快。</td>
</tr>
<tr>
<td><strong>数据处理</strong></td>
<td>MapReduce was designed to perform Batch Processing for a voluminous amount of data. Hence, for extended data processing, it is dependent on different engines like Storm, Giraph, Impala, etc. Managing many different components adds to the hassle.
<p>MapReduce无法交互处理数据</p>
</td>
<td>在同一个集群中执行批处理、实时处理、迭代处理、图形处理、机器学习和流式处理。因此，它是一个完整的数据分析引擎，足以处理所有需求。Spark具有高效处理实时流的能力。<br/> Spark可以交互处理数据。</td>
</tr>
<tr>
<td><strong>内存使用量</strong></td>
<td>不支持数据缓存。</td>
<td>通过在内存中缓存数据来提高系统性能。</td>
</tr>
<tr>
<td><strong>编码</strong></td>
<td>MapReduce需要处理低级API，因此开发人员需要对每个操作进行编码，这使得操作非常困难。</td>
<td>Spark易于使用，其弹性分布式数据集有助于使用高级操作符处理数据。它提供了丰富的Java、Scala、Python和r的API。</td>
</tr>
<tr>
<td>
<p><strong>等待时间</strong></p>
<p>潜伏意味着延迟。这是CPU向RAM发出请求后等待响应的时间。</p>
</td>
<td>MapReduce有一个高延迟的计算框架。</td>
<td>Spark提供了低延迟计算。</td>
</tr>
<tr>
<td><strong>从故障中恢复</strong></td>
<td>MapReduce具有高度容错能力，能够应对系统故障和失败。在这种情况下，如果出现故障，不需要从头重新启动应用程序。</td>
<td>Spark也是容错的。弹性分布式数据集[RDDs]允许在故障节点上恢复分区。它还支持通过检查点进行恢复，以减少对RDD的依赖性。因此，在失败的情况下，这里也不需要从头开始重新启动应用程序。</td>
</tr>
<tr>
<td><strong>调度器</strong></td>
<td>MapReduce依赖像Oozie这样的外部作业调度器来调度其复杂的流程。</td>
<td>由于内存中的计算，Spark的行为就像它自己的流调度程序。</td>
</tr>
<tr>
<td><strong>安全</strong></td>
<td>由于Kerberos的存在，MapReduce相对更安全。它还支持访问控制列表(ACL ),这是传统的文件权限模型。</td>
<td>Spark只支持一种认证，即共享密码认证。</td>
</tr>
<tr>
<td><strong>成本</strong></td>
<td>就成本而言，MapReduce是一个更便宜的选择。</td>
<td>Spark的成本更高，因为它需要内存处理能力和RAM。</td>
</tr>
<tr>
<td><strong>功能</strong></td>
<td>MapReduce是一个数据处理引擎。</td>
<td>Spark是一个数据分析引擎，因此是数据科学家的选择。</td>
</tr>
<tr>
<td><strong>框架</strong></td>
<td>它是一个开源框架，用于将数据写入HDFS，并处理HDFS的结构化和非结构化数据。</td>
<td>Spark是一个独立的实时处理引擎，可以安装在任何分布式文件系统中。</td>
</tr>
<tr>
<td><strong>支持的编程语言</strong></td>
<td>Java，C，C++，Ruby，Groovy，Perl，Python</td>
<td>Scala，Java，Python，R，SQL</td>
</tr>
<tr>
<td><strong> SQL支持</strong></td>
<td>使用Apache Hive运行SQL查询</td>
<td>使用Spark SQL运行<a href="https://hackr.io/blog/sql-commands"> SQL查询</a></td>
</tr>
<tr>
<td><strong>硬件要求</strong></td>
<td>MapReduce可以在商用硬件上运行。</td>
<td>Apache Spark需要中高级硬件配置才能高效运行。</td>
</tr>
<tr>
<td> </td>
<td>Hadoop需要一个机器学习工具，其中一个就是Apache Mahout。</td>
<td>Spark有自己的一套<a href="https://hackr.io/blog/what-is-machine-learning-definition-types">机器学习</a>即MLlib。</td>
</tr>
<tr>
<td><strong>冗余检查</strong></td>
<td>MapReduce不支持此功能。</td>
<td>Spark对每条记录只处理一次，因此消除了重复。</td>
</tr>
</tbody>
</div>    
</body>
</html>